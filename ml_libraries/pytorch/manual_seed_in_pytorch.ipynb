{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b15ac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b2fa7",
   "metadata": {},
   "source": [
    "`torch.manual_seed()`, `np.random.seed()`, and `random.seed()` ‚Äî what they do, what happens with and without seeds, and simple code examples you can run to understand the concept deeply.\n",
    "\n",
    "---\n",
    "\n",
    "## üî• **What Is a Seed?**\n",
    "\n",
    "Whenever you generate random numbers (for ML, sampling, splitting datasets, initializing weights), computers use a **pseudo-random number generator (PRNG)**.\n",
    "\n",
    "A **seed** is the *starting point* for this PRNG.\n",
    "If you use the **same seed**, you get **the same sequence of \"random\" numbers** every time ‚Äî which makes experiments **reproducible**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Why Do We Use Seeds?**\n",
    "\n",
    "#### ‚úî To reproduce model results exactly\n",
    "\n",
    "Same model + same data + same seed = same outputs.\n",
    "\n",
    "#### ‚úî For debugging\n",
    "\n",
    "You can test multiple things while keeping randomness fixed.\n",
    "\n",
    "#### ‚úî For teaching / tutorials\n",
    "\n",
    "Everyone sees the exact same numbers.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùå **What Happens If You Don‚Äôt Use a Seed?**\n",
    "\n",
    "* Each run generates **different random numbers**.\n",
    "* Weight initialization changes ‚Üí model performance varies.\n",
    "* Train/validation splits change.\n",
    "* Sampling / augmentations differ.\n",
    "* Harder to debug because every run is different.\n",
    "\n",
    "---\n",
    "\n",
    "## üå± **What Happens When You Use a Seed?**\n",
    "\n",
    "* Random numbers become **predictable** and **repeatable**.\n",
    "* Same code ‚Üí same output, every run.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Three Types of Seeds You Encounter\n",
    "\n",
    "### 1Ô∏è‚É£ **PyTorch** ‚Üí `torch.manual_seed()`\n",
    "\n",
    "Controls randomness in:\n",
    "\n",
    "* torch.rand()\n",
    "* weight initialization in nn.Module\n",
    "* dropout randomness\n",
    "* some CUDA operations (if you also set cuda seeds)\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "print(torch.randn(3))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ **NumPy** ‚Üí `np.random.seed()`\n",
    "\n",
    "Controls randomness in:\n",
    "\n",
    "* np.random.rand()\n",
    "* np.random.randint()\n",
    "* NumPy-based dataset shuffling\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "print(np.random.rand(3))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ **Python‚Äôs built-in random** ‚Üí `random.seed()`\n",
    "\n",
    "Controls randomness in:\n",
    "\n",
    "* random.random()\n",
    "* random.shuffle()\n",
    "* random.choice()\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "print(random.random())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ **Now Let's See Effects With & Without Seeds**\n",
    "\n",
    "---\n",
    "\n",
    "### üî¨ **A. PyTorch Example**\n",
    "\n",
    "#### ‚ùå Without Seed ‚Üí Different results\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "print(torch.randn(3))\n",
    "print(torch.randn(3))\n",
    "```\n",
    "\n",
    "Running twice ‚Üí different outputs each time:\n",
    "\n",
    "```\n",
    "tensor([ 0.34, -1.23,  0.89])\n",
    "tensor([-0.56,  0.44,  1.03])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úî With Seed ‚Üí Same results every time\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "print(torch.randn(3))\n",
    "\n",
    "torch.manual_seed(0)\n",
    "print(torch.randn(3))\n",
    "```\n",
    "\n",
    "Both prints are identical:\n",
    "\n",
    "```\n",
    "tensor([ 1.5410, -0.2934, -2.1788])\n",
    "tensor([ 1.5410, -0.2934, -2.1788])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üî¨ **B. NumPy Example**\n",
    "\n",
    "#### ‚ùå Without Seed\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "print(np.random.rand(3))\n",
    "print(np.random.rand(3))\n",
    "```\n",
    "\n",
    "Different values each run.\n",
    "```\n",
    "[0.04170374 0.4521037  0.88870225]\n",
    "[0.59730074 0.04363884 0.14128526]\n",
    "```\n",
    "\n",
    "#### ‚úî With Seed\n",
    "\n",
    "```python\n",
    "np.random.seed(10)\n",
    "print(np.random.rand(3))\n",
    "np.random.seed(10)\n",
    "print(np.random.rand(3))\n",
    "```\n",
    "\n",
    "Same values every time.\n",
    "```\n",
    "[0.77132064 0.02075195 0.63364823]\n",
    "[0.77132064 0.02075195 0.63364823]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üî¨ **C. Python Random Example**\n",
    "\n",
    "#### ‚ùå Without Seed\n",
    "\n",
    "```python\n",
    "import random\n",
    "print(random.randint(1, 100))\n",
    "print(random.randint(1, 100))\n",
    "```\n",
    "Different values each run.\n",
    "```\n",
    "37\n",
    "74\n",
    "```\n",
    "\n",
    "#### ‚úî With Seed\n",
    "\n",
    "```python\n",
    "random.seed(10)\n",
    "print(random.randint(1, 100))\n",
    "random.seed(10)\n",
    "print(random.randint(1, 100))\n",
    "```\n",
    "\n",
    "Repeatable output.\n",
    "```\n",
    "22\n",
    "22\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö† Important Note\n",
    "\n",
    "**Setting torch seed does NOT affect numpy or python random.**\n",
    "They are **separate random generators**.\n",
    "\n",
    "For complete reproducibility:\n",
    "\n",
    "```python\n",
    "import torch, numpy as np, random\n",
    "\n",
    "seed = 42\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Mini Playground: Compare All Three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f138ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Without seed ---\n",
      "torch: tensor([-0.6327, -0.8037])\n",
      "numpy: [0.14787571 0.02946387]\n",
      "random: 0.3630060300163579\n",
      "torch: tensor([-0.3769, -0.3311])\n",
      "numpy: [0.88031975 0.33720731]\n",
      "random: 0.8694150569483021\n",
      "\n",
      "--- With seed = 123 ---\n",
      "torch: tensor([-0.1115,  0.1204])\n",
      "numpy: [0.69646919 0.28613933]\n",
      "random: 0.052363598850944326\n",
      "torch: tensor([-0.1115,  0.1204])\n",
      "numpy: [0.69646919 0.28613933]\n",
      "random: 0.052363598850944326\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Without seed ---\")\n",
    "print(\"torch:\", torch.randn(2))\n",
    "print(\"numpy:\", np.random.rand(2))\n",
    "print(\"random:\", random.random())\n",
    "\n",
    "# Repeat to show difference\n",
    "print(\"torch:\", torch.randn(2))\n",
    "print(\"numpy:\", np.random.rand(2))\n",
    "print(\"random:\", random.random())\n",
    "\n",
    "print(\"\\n--- With seed = 123 ---\")\n",
    "torch.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "\n",
    "print(\"torch:\", torch.randn(2))\n",
    "print(\"numpy:\", np.random.rand(2))\n",
    "print(\"random:\", random.random())\n",
    "\n",
    "# Repeat to show SAME numbers\n",
    "torch.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "\n",
    "print(\"torch:\", torch.randn(2))\n",
    "print(\"numpy:\", np.random.rand(2))\n",
    "print(\"random:\", random.random())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe09a2dc",
   "metadata": {},
   "source": [
    "## üß† Final Summary (Easy Memorable Points)\n",
    "\n",
    "#### **1. Seeds freeze randomness.**\n",
    "\n",
    "Same seed ‚Üí same results.\n",
    "\n",
    "#### **2. Each library has its own seed.**\n",
    "\n",
    "* PyTorch ‚Üí `torch.manual_seed()`\n",
    "* NumPy ‚Üí `np.random.seed()`\n",
    "* Python ‚Üí `random.seed()`\n",
    "\n",
    "#### **3. Without seeds ‚Üí every run differs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbdb3e9",
   "metadata": {},
   "source": [
    "## Question:\n",
    "```\n",
    "Below given code I applied torch seed, but second and third print didn't give same results like first print, why so?\n",
    "\n",
    "torch.manual_seed(3)\n",
    "print(torch.randn(3))\n",
    "print(torch.randn(3))\n",
    "print(torch.randn(3))\n",
    "````\n",
    "\n",
    "\n",
    "### ‚úÖ **Why second and third prints are different even after torch.manual_seed()?**\n",
    "\n",
    "Because:\n",
    "\n",
    "#### üëâ **`torch.manual_seed(3)` only sets the seed *once*, at that moment.**\n",
    "\n",
    "After that, every call to `torch.randn()` continues the random sequence.\n",
    "\n",
    "It does **NOT** restart the sequence for every new `print()`\n",
    "unless you **set the seed again**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Example Breakdown\n",
    "\n",
    "Your code:\n",
    "\n",
    "```python\n",
    "torch.manual_seed(3)\n",
    "print(torch.randn(3))   # Output A\n",
    "print(torch.randn(3))   # Output B (next numbers in sequence)\n",
    "print(torch.randn(3))   # Output C (next numbers in sequence)\n",
    "```\n",
    "\n",
    "Here‚Äôs what happens internally:\n",
    "\n",
    "1. You set seed ‚Üí random sequence starts from fixed point.\n",
    "2. First `randn` ‚Üí uses values 1,2,3 from the sequence.\n",
    "3. Second `randn` ‚Üí uses values 4,5,6 from the same sequence.\n",
    "4. Third `randn` ‚Üí uses values 7,8,9.\n",
    "\n",
    "So **they are different outputs ‚Äî but they are consistently reproducible each run.**\n",
    "\n",
    "Run the above code 10 times ‚Üí all 10 will produce the *same three different rows*.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ If you want the SAME output each time, you must reset the seed:\n",
    "\n",
    "```python\n",
    "torch.manual_seed(3)\n",
    "print(torch.randn(3))\n",
    "\n",
    "torch.manual_seed(3)\n",
    "print(torch.randn(3))\n",
    "\n",
    "torch.manual_seed(3)\n",
    "print(torch.randn(3))\n",
    "```\n",
    "\n",
    "Now all three outputs will match.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úî Why does this work?\n",
    "\n",
    "Each time you call `torch.manual_seed(3)`, you restart the PRNG at the same point, so `torch.randn(3)` always gives the same numbers.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Summary (Super Clear)\n",
    "\n",
    "#### ‚ùå One seed ‚Üí different outputs\n",
    "\n",
    "```\n",
    "seed ‚Üí rand ‚Üí next rand ‚Üí next rand\n",
    "```\n",
    "\n",
    "#### ‚úî Reset seed before each call ‚Üí same output\n",
    "\n",
    "```\n",
    "seed ‚Üí rand\n",
    "seed ‚Üí rand\n",
    "seed ‚Üí rand\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b29b6c0",
   "metadata": {},
   "source": [
    "## Question:\n",
    "\n",
    "```\n",
    "so I've observed in model training scripts this seed is set at the begning, so i want to understand what id the difference when we set seed once and when we set seed at every step?\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ **Difference Between Setting Seed ONCE vs Setting Seed EVERY TIME**\n",
    "\n",
    "#### ‚úî **1. Setting seed ONCE (normal / recommended)**\n",
    "\n",
    "This is what you usually see:\n",
    "\n",
    "```python\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "numpy.random.seed(seed)\n",
    "random.seed(seed)\n",
    "```\n",
    "\n",
    "##### üëâ What this means:\n",
    "\n",
    "You start the random number generator from a fixed point **one time**, and then let randomness progress **naturally** during training.\n",
    "\n",
    "##### üéØ This ensures:\n",
    "\n",
    "* Model initialization is the same each run\n",
    "* Data shuffling is the same\n",
    "* Dropout randomness is the same\n",
    "* Augmentations are the same\n",
    "* Training path is identical on every run\n",
    "\n",
    "##### BUT IMPORTANT:\n",
    "\n",
    "Even though training steps involve randomness (dropout, sampling, shuffling),\n",
    "**they are still reproducible** because they follow the **same sequence of random numbers** for each run.\n",
    "\n",
    "##### üîç Example:\n",
    "\n",
    "```\n",
    "Seed fixed ‚Üí random sequence A, B, C, D, E, F ...\n",
    "Training uses: A ‚Üí B ‚Üí C ‚Üí D ‚Üí ...\n",
    "```\n",
    "\n",
    "Next run:\n",
    "\n",
    "```\n",
    "Seed fixed ‚Üí same sequence A, B, C, D ...\n",
    "```\n",
    "\n",
    "So both runs behave the same.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùå **2. Setting seed on EVERY step (NOT recommended)**\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "for batch in data:\n",
    "    torch.manual_seed(42)\n",
    "    ...\n",
    "    output = model(batch)\n",
    "```\n",
    "\n",
    "##### üëâ What this means:\n",
    "\n",
    "You **restart the random generator** at the same point every iteration.\n",
    "\n",
    "##### ‚ùå Consequences:\n",
    "\n",
    "* Dropout will ALWAYS drop the exact same neurons ‚Üí model never learns properly\n",
    "* Data augmentations will ALWAYS be identical every epoch ‚Üí no variation\n",
    "* Weight updates follow an unnatural, repetitive pattern\n",
    "* Training becomes biased and unrealistic\n",
    "* Model can overfit or fail to converge\n",
    "\n",
    "##### üîç Example:\n",
    "\n",
    "```\n",
    "Reset seed ‚Üí always produce A\n",
    "Reset seed ‚Üí always produce A\n",
    "Reset seed ‚Üí always produce A\n",
    "```\n",
    "\n",
    "You get the **same ‚Äúrandom‚Äù number** repeatedly.\n",
    "This kills the entire purpose of randomness in training.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† **Why Setting Seed Once Works Perfectly for Training**\n",
    "\n",
    "Because the seed does **not guarantee same random value every time**,\n",
    "it guarantees **the same random *sequence***.\n",
    "\n",
    "ML training heavily depends on sequential randomness:\n",
    "\n",
    "* weight initialization\n",
    "* dropout masks\n",
    "* batch shuffling\n",
    "* augmentation randomness\n",
    "* optimizer stochastic behaviour\n",
    "\n",
    "Setting a seed ONCE preserves the randomness **but in a controlled, repeatable way**.\n",
    "\n",
    "---\n",
    "\n",
    "### ü§Ø Small Demonstration to Understand This Deeply\n",
    "\n",
    "##### 1Ô∏è‚É£ **Seed once (good):**\n",
    "\n",
    "```python\n",
    "torch.manual_seed(10)\n",
    "print(torch.randn(3))  # A\n",
    "print(torch.randn(3))  # B\n",
    "```\n",
    "\n",
    "Each run ‚Üí A and B same.\n",
    "\n",
    "---\n",
    "\n",
    "##### 2Ô∏è‚É£ **Seed every time (bad):**\n",
    "\n",
    "```python\n",
    "torch.manual_seed(10)\n",
    "print(torch.randn(3))  # A\n",
    "\n",
    "torch.manual_seed(10)\n",
    "print(torch.randn(3))  # A (same)\n",
    "\n",
    "torch.manual_seed(10)\n",
    "print(torch.randn(3))  # A (same)\n",
    "```\n",
    "\n",
    "Destroyed randomness.\n",
    "\n",
    "---\n",
    "\n",
    "# üß® **In Deep Learning Terms**\n",
    "\n",
    "| Setting seed once                                | Setting seed every time                 |\n",
    "| ------------------------------------------------ | --------------------------------------- |\n",
    "| ‚úî Same results every run                         | ‚ùå Repeated identical randomness         |\n",
    "| ‚úî Training behaves normally                      | ‚ùå Bad training dynamics                 |\n",
    "| ‚úî Shuffling varies across batch but reproducible | ‚ùå Always same shuffle                   |\n",
    "| ‚úî Dropout varies but reproducible                | ‚ùå Dropout mask same every step          |\n",
    "| ‚úî Convergence is valid                           | ‚ùå Convergence fails or becomes unstable |\n",
    "| üåü BEST PRACTICE                                 | üö´ NEVER DO THIS                        |\n",
    "\n",
    "---\n",
    "\n",
    "### üèÅ Final Summary\n",
    "\n",
    "##### üëâ **Setting seed once = reproducible but still realistic randomness**\n",
    "\n",
    "This is what we want for model training.\n",
    "\n",
    "##### üëâ **Setting seed repeatedly = destroys randomness**\n",
    "\n",
    "This breaks dropout, augmentation, shuffling, convergence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b67173",
   "metadata": {},
   "source": [
    "## üöÄ **What is `torch.cuda.manual_seed_all()` ?**\n",
    "\n",
    "`torch.cuda.manual_seed_all(seed)`\n",
    "sets the **random seed for ALL CUDA GPUs** being used by PyTorch.\n",
    "\n",
    "That means:\n",
    "\n",
    "* random tensors created **on GPU**\n",
    "* GPU-based random operations\n",
    "* CUDA kernels with randomness\n",
    "* multi-GPU training randomness\n",
    "\n",
    "‚Ä¶will all follow a **reproducible random sequence**.\n",
    "\n",
    "---\n",
    "\n",
    "## üî• Why do we need it?\n",
    "\n",
    "Because **CUDA randomness is separate from CPU randomness**.\n",
    "\n",
    "#### ‚ùóImportant:\n",
    "\n",
    "`torch.manual_seed(seed)` only sets the seed for **CPU operations**.\n",
    "\n",
    "It does **NOT** affect GPU randomness.\n",
    "\n",
    "So this:\n",
    "\n",
    "```python\n",
    "torch.manual_seed(42)\n",
    "torch.randn(3, device=\"cuda\")\n",
    "```\n",
    "\n",
    "will still produce **unpredictable results** (different each run!)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ To make GPU randomness reproducible:\n",
    "\n",
    "```python\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "```\n",
    "\n",
    "Now:\n",
    "\n",
    "* CPU random ops ‚Üí reproducible\n",
    "* GPU random ops ‚Üí reproducible\n",
    "* Multi-GPU (if using DDP) ‚Üí reproducible\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Quick Example\n",
    "\n",
    "#### ‚ùå Without CUDA seed (unpredictable)\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)             # CPU seed only\n",
    "print(torch.randn(3, device=\"cuda\"))\n",
    "print(torch.randn(3, device=\"cuda\"))\n",
    "```\n",
    "\n",
    "Each run ‚Üí different results.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úî With CUDA seed (predictable)\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)             # CPU\n",
    "torch.cuda.manual_seed_all(0)    # GPU\n",
    "\n",
    "print(torch.randn(3, device=\"cuda\"))\n",
    "print(torch.randn(3, device=\"cuda\"))\n",
    "```\n",
    "\n",
    "Run it 10 times ‚Üí always identical results.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå What does \"manual_seed_all\" mean?\n",
    "\n",
    "It applies the seed to **all GPUs** your system is using.\n",
    "\n",
    "If you have:\n",
    "\n",
    "* 1 GPU ‚Üí same effect as `torch.cuda.manual_seed()`\n",
    "* 4 GPUs ‚Üí applies the seed to all 4 devices\n",
    "\n",
    "This matters in **Distributed Data Parallel (DDP)** training.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Full Reproducibility Block\n",
    "\n",
    "When people want **exact same training results**, they usually write:\n",
    "\n",
    "```python\n",
    "import torch, random, numpy as np\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# python random\n",
    "random.seed(seed)\n",
    "\n",
    "# NumPy random\n",
    "np.random.seed(seed)\n",
    "\n",
    "# PyTorch CPU random\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# PyTorch GPU random (all GPUs)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# For determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "```\n",
    "\n",
    "This ensures:\n",
    "\n",
    "* CPU randomness ‚Üí fixed\n",
    "* CUDA randomness ‚Üí fixed\n",
    "* cuDNN kernels ‚Üí deterministic\n",
    "\n",
    "---\n",
    "\n",
    "## üß® Important Note\n",
    "\n",
    "#### `torch.cuda.manual_seed_all()` does NOT make CUDA **completely deterministic**.\n",
    "\n",
    "Some GPU operations in PyTorch still use:\n",
    "\n",
    "* non-deterministic atomic operations\n",
    "* parallel kernels whose behavior varies slightly\n",
    "\n",
    "That‚Äôs why we also use:\n",
    "\n",
    "```python\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üèÅ Summary (Simple & Clean)\n",
    "\n",
    "#### ‚úî `torch.manual_seed(seed)`\n",
    "\n",
    "‚Üí Seeds **CPU** RNG.\n",
    "\n",
    "#### ‚úî `torch.cuda.manual_seed(seed)`\n",
    "\n",
    "‚Üí Seeds **current GPU's** RNG.\n",
    "\n",
    "#### ‚úî `torch.cuda.manual_seed_all(seed)`\n",
    "\n",
    "‚Üí Seeds **all GPUs** (good for multi-GPU training).\n",
    "\n",
    "#### ‚ùå Using only CPU seed does NOT control GPU randomness.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
